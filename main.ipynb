{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d68d55a",
   "metadata": {},
   "source": [
    "### Download and compute data\n",
    "\n",
    "Launch this next code line, if you didn't download data yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a68a5964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Annual Volatility :\n",
      "USO     0.375213\n",
      "URTH    0.169749\n",
      "GLD     0.145473\n",
      "dtype: float64\n",
      "/Users/hugo/Documents/Finance/projet/OptiFolio/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:7654: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n",
      "/Users/hugo/Documents/Finance/projet/OptiFolio/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:7654: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "!python utils/dataHandler.py\n",
    "!python utils/datasetHandler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "703cc94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import OptiFolioEnv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Dirichlet\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "43299e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/dataset/dataset.csv\"\n",
    "dataset_return_path = \"data/returns/data_returns.csv\"\n",
    "df = pd.read_csv(dataset_path, index_col=\"Date\")\n",
    "return_df = pd.read_csv(dataset_return_path, index_col=\"Date\")\n",
    "\n",
    "train_df, test_df = train_test_split(df,test_size=0.2, shuffle=False)\n",
    "\n",
    "train_df.to_csv(\"data/dataset/train/train.csv\")\n",
    "test_df.to_csv(\"data/dataset/train/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d4a3c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOActorCritic(nn.Module):\n",
    "    def __init__(self, input_shape, action_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_shape[0] * input_shape[1]\n",
    "        self.action_dim = action_dim\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.actor_alpha = nn.Sequential(\n",
    "            nn.Linear(256, action_dim),\n",
    "            nn.Softplus()  \n",
    "        )\n",
    "\n",
    "        self.critic = nn.Linear(256, 1)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.orthogonal_(m.weight, gain=1.0)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        nn.init.orthogonal_(self.actor_alpha[0].weight, gain=0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(0)\n",
    "\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        features = self.shared(x)\n",
    "\n",
    "        alpha = self.actor_alpha(features) + 1e-6\n",
    "        value = self.critic(features)\n",
    "\n",
    "        return alpha, value\n",
    "\n",
    "    def get_action(self, x):\n",
    "        alpha, value = self.forward(x)\n",
    "        dist = Dirichlet(alpha)\n",
    "\n",
    "        action = dist.sample()\n",
    "        log_prob = dist.log_prob(action)\n",
    "\n",
    "        return action, log_prob, value\n",
    "\n",
    "    def evaluate_actions(self, x, actions):\n",
    "        alpha, value = self.forward(x)\n",
    "        dist = Dirichlet(alpha)\n",
    "\n",
    "        log_probs = dist.log_prob(actions)\n",
    "        entropy = dist.entropy()\n",
    "\n",
    "        return log_probs, entropy, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f11e532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test du modèle...\n",
      "Valeur finale du portefeuille : 1345.53\n",
      "Poids Finaux : [0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "train_env = OptiFolioEnv(dataframe=train_df, return_data=return_df, initial_amount=1000, lookback=62)\n",
    "test_env = OptiFolioEnv(dataframe=test_df, return_data=return_df, initial_amount=1000, lookback=62)\n",
    "\n",
    "m_train_env = Monitor(train_env)\n",
    "m_test_env = Monitor(test_env)\n",
    "\n",
    "model = PPO(\n",
    "    policy=\"MlpPolicy\", \n",
    "    env=m_train_env,\n",
    "    learning_rate=1e-4,\n",
    "    n_steps=2048,           \n",
    "    batch_size=64,          \n",
    "    gamma=0.99,             \n",
    "    verbose=0,\n",
    "    tensorboard_log=\"./ppo_trading_logs/\"\n",
    ")\n",
    "\n",
    "#print(\"Début de l'apprentissage...\")\n",
    "#model.learn(total_timesteps=3_000_000, progress_bar=True)\n",
    "\n",
    "#model.save(\"model/ppo_optifolio_v1\")\n",
    "\n",
    "print(\"Test du modèle...\")\n",
    "model.load(\"model/ppo_optifolio_v1\")\n",
    "obs, info = m_test_env.reset()\n",
    "done = False\n",
    "history_portfolio = []\n",
    "\n",
    "while not done:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    weights = action / (np.sum(action) + 1e-8) \n",
    "    \n",
    "    obs, reward, terminated, truncated, info = m_test_env.step(weights)\n",
    "    history_portfolio.append(info['portfolio_value'])\n",
    "    history_portfolio.append(info['weights'])\n",
    "    done = terminated or truncated\n",
    "\n",
    "print(f\"Valeur finale du portefeuille : {info['portfolio_value']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "91657e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "clean_weights = []\n",
    "clean_values = []\n",
    "\n",
    "for item in history_portfolio:\n",
    "    if np.isscalar(item) or (isinstance(item, np.ndarray) and item.ndim == 0):\n",
    "        clean_values.append(item)\n",
    "    \n",
    "    elif isinstance(item, (list, np.ndarray, tuple)):\n",
    "        if hasattr(item, 'tolist'):\n",
    "            clean_weights.append(item.tolist())\n",
    "        else:\n",
    "            clean_weights.append(item)\n",
    "\n",
    "weights_df = pd.DataFrame(clean_weights)\n",
    "\n",
    "weights_df.columns = [\"USO\",\"URTH\",\"GLD\"]\n",
    "\n",
    "aligned_index_weights = test_df.index[-len(weights_df):]\n",
    "weights_df.index = aligned_index_weights\n",
    "\n",
    "weights_df.to_csv(\"model/results/Weights_evo.csv\")\n",
    "\n",
    "if len(clean_values) > 0:\n",
    "    portfolio_df = pd.DataFrame(clean_values, columns=['Portfolio_Value'])\n",
    "    \n",
    "    aligned_index_vals = test_df.index[-len(portfolio_df):]\n",
    "    portfolio_df.index = aligned_index_vals\n",
    "    \n",
    "    portfolio_df.to_csv(\"model/results/Portfolio_evo.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
