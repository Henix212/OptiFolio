{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d68d55a",
   "metadata": {},
   "source": [
    "### Download and compute data\n",
    "\n",
    "Launch this next code line, if you didn't download data yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a5964",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python utils/dataHandler.py\n",
    "!python utils/datasetHandler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "703cc94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43299e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/dataset/dataset.csv\"\n",
    "df = pd.read_csv(dataset_path, index_col=\"Date\")\n",
    "\n",
    "train_df, test_df = train_test_split(df,test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a3c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(PPO, self).__init__()\n",
    "        self.hidden_layer1 = nn.Linear(state_dim,128)\n",
    "        self.hidden_layer2 = nn.Linear(128,128)\n",
    "        self.critic = nn.Linear(128,1)\n",
    "        self.actor = nn.Linear(128,action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden_layer1(x))\n",
    "        x = torch.relu(self.hidden_layer2(x))\n",
    "        action_probs = torch.softmax(self.actor(x), dim=-1)\n",
    "        state_value = self.critic(x)\n",
    "        return action_probs, state_value\n",
    "    \n",
    "\n",
    "def init_weights(m):\n",
    "  if type(m) == nn.Linear:\n",
    "    nn.init.xavier_uniform_(m.weight)\n",
    "    m.bias.data.fill_(0.01)\n",
    "\n",
    "def initialize_ppo_model(device,state_dim,action_dim):\n",
    "    \"\"\"\n",
    "    Initialize the PPO model, optimizer, and loss function.\n",
    "    \"\"\"\n",
    "    model = PPO(state_dim, action_dim).to(device)\n",
    "    model.apply(init_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    mse_loss = nn.MSELoss()\n",
    "    return model, optimizer, mse_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
